{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import scipy.io.wavfile\n",
    "\n",
    "cutoffFreq = 100\n",
    "period_range = [1, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortFFT(signal, wf, step_length, lambdaP = 0.2):\n",
    "    windowSize = len(wf)\n",
    "    audio_length = len(signal)\n",
    "    to_pad = int(np.floor(windowSize / 2))\n",
    "    number_times = (int(lambdaP*5) + int(np.ceil(((2 * to_pad + audio_length) - windowSize) / step_length)))\n",
    "    audio_stft = np.zeros((windowSize, number_times))\n",
    "    signal = np.pad(signal,(to_pad,(number_times * step_length+ (windowSize - step_length)- to_pad)- audio_length,),\"constant\",constant_values=0)\n",
    "    for j in range(number_times * int(lambdaP * 5)):\n",
    "        audio_stft[:, j] = wf * signal[j*step_length : j*step_length + windowSize] \n",
    "    return np.fft.fft(audio_stft, axis=0)\n",
    "\n",
    "def inverseSTFT(transformed_audio, wf, step_length,lambdaP=0.2):\n",
    "    transformed_audio = np.real(np.fft.ifft(transformed_audio, axis=0))\n",
    "    window_length, total_times = np.shape(transformed_audio)\n",
    "\n",
    "    number_samples= (window_length - step_length)\n",
    "    number_samples+= total_times * step_length\n",
    "    signal = np.zeros(number_samples)\n",
    "\n",
    "    for j in range(total_times):\n",
    "        alpha = j*step_length\n",
    "        signal[alpha : alpha + window_length] = transformed_audio[:, j] + (signal[alpha : alpha + window_length])\n",
    "    signal = signal[window_length - step_length +int(lambdaP): number_samples - (window_length - step_length)]#padding removal\n",
    "    return signal / sum(wf[0:window_length:step_length])\n",
    "\n",
    "def computeAutocorrelation(data_matrix):\n",
    "    nRows = data_matrix.shape[0]\n",
    "\n",
    "    # Compute the power spectral density (PSD) of the columns with no padding\n",
    "    data_matrix = np.power(np.abs(np.fft.fft(data_matrix, n=(2 * nRows), axis=0)), 2)\n",
    "\n",
    "    # Reference: Wienerâ€“Khinchin theorem\n",
    "    autocorrelation_matrix = np.real(np.fft.ifft(data_matrix, axis=0))\n",
    "    autocorrelation_matrix = autocorrelation_matrix[0:nRows, :]\n",
    "    autocorrelation_matrix = np.divide(autocorrelation_matrix, np.arange(nRows, 0, -1)[:, np.newaxis])\n",
    "    \n",
    "    return autocorrelation_matrix\n",
    "\n",
    "\n",
    "def computeBeatSpectrum(audio_spectrogram):\n",
    "    beat_spectrum = computeAutocorrelation(audio_spectrogram.T)\n",
    "    return np.mean(beat_spectrum, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def getPeriods(B, period_range):\n",
    "    if B.ndim == 1:\n",
    "        periods = (1 + np.argmax(B[period_range[0] : min(period_range[1], int(np.floor(B.shape[0] / 3)))]))\n",
    "    else:\n",
    "        periods = (1 + np.argmax(B[period_range[0] : min(period_range[1], int(np.floor(B.shape[0] / 3))),:,],axis=0))\n",
    "    return periods + period_range[0]\n",
    "\n",
    "\n",
    "\n",
    "def _mask(a_spectogram, repeating_period,lambdaP=0.2):\n",
    "    nFreq, totalTimes = np.shape(a_spectogram)\n",
    "    number_segments = int(np.ceil(totalTimes / repeating_period))\n",
    "\n",
    "    a_spectogram = np.pad(a_spectogram,((0, 0), (0, number_segments * repeating_period - totalTimes + int(lambdaP))),\"constant\",constant_values=0)\n",
    "    a_spectogram = np.reshape(a_spectogram,(nFreq, repeating_period, number_segments),order=\"F\")\n",
    "\n",
    "    # Compute the repeating segment by taking the median over the segments, not accounting for the last zeros\n",
    "    rep_seg = np.concatenate(\n",
    "        (\n",
    "            np.median(a_spectogram[:, 0 : totalTimes - number_segments * repeating_period - repeating_period, :],2),\n",
    "            np.median(a_spectogram[:,totalTimes- number_segments * repeating_period -repeating_period: repeating_period,0 : number_segments - 1,],2),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    repeating_spectrogram = np.minimum(a_spectogram, rep_seg[:, :, np.newaxis])\n",
    "\n",
    "    repeating_mask = (np.finfo(float).eps + repeating_spectrogram ) / (np.finfo(float).eps + a_spectogram)\n",
    "    repeating_mask = np.reshape(repeating_mask,(nFreq, number_segments * repeating_period),order=\"F\")\n",
    "\n",
    "    return repeating_mask[:, 0:totalTimes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sepRepet(audio_signal, sampling_frequency):\n",
    "    # Get the number of samples and channels in the audio signal\n",
    "    nSamples, nChannels = np.shape(audio_signal)\n",
    "    window_length = pow(2, int(np.ceil(np.log2(0.04 * sampling_frequency))))\n",
    "    window_function = scipy.signal.hamming(window_length, sym=False)\n",
    "    step_length = window_length//2\n",
    "    print(type(window_length))\n",
    "    nTimes = (int(np.ceil(((2 * int(np.floor(window_length / 2)) + nSamples )- window_length)/ step_length))+ 1)\n",
    "\n",
    "    audio_stft = np.zeros((window_length, nTimes, nChannels), dtype=complex)\n",
    "    print(\"stft: \",audio_stft.shape)\n",
    "\n",
    "    for i in range(nChannels):\n",
    "        audio_stft[:, :, i] = shortFFT(audio_signal[:, i], window_function, step_length)\n",
    "\n",
    "    audio_spectrogram = abs(audio_stft[0 : step_length + 1, :, :])\n",
    "    beat_spectrum = computeBeatSpectrum(np.power(np.mean(audio_spectrogram, axis=2), 2))\n",
    "\n",
    "    background_signal = np.zeros((nSamples, nChannels))\n",
    "    repeating_period = getPeriods(beat_spectrum, np.round(np.array(period_range) * sampling_frequency / step_length).astype(int))\n",
    "\n",
    "    for i in range(nChannels):\n",
    "        repeating_mask = _mask(audio_spectrogram[:, :, i], repeating_period)\n",
    "        #high-pass filtering\n",
    "        repeating_mask[1 : round(cutoffFreq * window_length / sampling_frequency) + 1, :] = 1\n",
    "\n",
    "        # Recover the mirrored frequencies\n",
    "        repeating_mask = np.concatenate((repeating_mask, repeating_mask[-2:0:-1, :]), axis=0)\n",
    "\n",
    "        background_signal_inverseTransformed = inverseSTFT(repeating_mask * audio_stft[:, :, i],window_function,step_length)\n",
    "        background_signal[:, i] = background_signal_inverseTransformed[0:nSamples]\n",
    "\n",
    "    return background_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavread(audio_file):\n",
    "    sf, A_S = scipy.io.wavfile.read(audio_file)\n",
    "    return A_S / (pow(2, 8 * A_S.itemsize)/2), sf #normalization, 8 times the number of bytes is the bit-depth, gives range [-1,1]\n",
    "\n",
    "\n",
    "def wavwrite(audio_signal, sampling_frequency, audio_file):\n",
    "\n",
    "    scipy.io.wavfile.write(audio_file, sampling_frequency, audio_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_S, sf = wavread(\"audio2.wav\")\n",
    "\n",
    "# # Estimate the background signal, and the foreground signal\n",
    "# background_signal = sepRepet(A_S, sf)\n",
    "# foreground_signal = A_S-background_signal\n",
    "# # background_signal2 = sepRepet(foreground_signal,sf)\n",
    "# # foreground_signal2 = foreground_signal - background_signal2\n",
    "# # background_signal+=background_signal2\n",
    "# # foreground_signal=foreground_signal2\n",
    "\n",
    "# # foreground_signal[foreground_signal<0.000001] = 0\n",
    "# #new_foreground_signal --> subtract the audio out where the person is not speaking\n",
    "# #new_background_signal = audio-signal - new_foreground_signal\n",
    "\n",
    "# # Write the background and foreground signals\n",
    "# scipy.io.wavfile.write(\"audio2bg_project.wav\", sf,background_signal )\n",
    "# scipy.io.wavfile.write(\"audio2fg_project.wav\", sf,foreground_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def calculate_snr(original_signal, separated_signal):\n",
    "    # Ensure the signals have the same length\n",
    "    min_length = min(len(original_signal), len(separated_signal))\n",
    "    original_signal = original_signal[:min_length]\n",
    "    separated_signal = separated_signal[:min_length]\n",
    "    # original_signal /= np.max(np.abs(original_signal))\n",
    "    # separated_signal /= np.max(np.abs(separated_signal))\n",
    "    # print(original_signal.shape)\n",
    "    # print(separated_signal.shape)\n",
    "    # np.savetxt(\"orig.txt\",original_signal[:1000000])\n",
    "    # np.savetxt(\"sep.txt\",separated_signal[:1000000])\n",
    "    # Compute the power of the original signal\n",
    "    power_original = np.sum(original_signal**2)\n",
    "\n",
    "    # Compute the power of the noise (difference between original and separated)\n",
    "    noise = original_signal - separated_signal\n",
    "    \n",
    "    power_noise = np.sum(noise**2)\n",
    "\n",
    "    # Calculate SNR in dB\n",
    "    snr = 10 * np.log10(power_original / power_noise)\n",
    "\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def genReport(audio_folder):\n",
    "    for audio_file in os.listdir(audio_folder):\n",
    "        if not str.endswith(audio_file,\".wav\"):\n",
    "            continue\n",
    "        filePath = os.path.join(audio_folder,audio_file)\n",
    "        print(filePath)\n",
    "        A_S, sf = wavread(filePath) \n",
    "        background_signal = sepRepet(A_S, sf)\n",
    "        foreground_signal = A_S-background_signal\n",
    "        folderPath = os.path.join(audio_folder,os.path.splitext(audio_file)[0])\n",
    "        os.makedirs(folderPath, exist_ok=True)\n",
    "        scipy.io.wavfile.write(os.path.join(folderPath,(audio_file + \"_background_signal.wav\")), sf,background_signal)\n",
    "        scipy.io.wavfile.write(os.path.join(folderPath,(audio_file + \"_foreground_signal.wav\")), sf,foreground_signal)\n",
    "        with open(os.path.join(folderPath,\"report.txt\"), 'w') as reportfile:\n",
    "            value_to_write = [\"Audio Name: \" + audio_file,\n",
    "                              \"Background SNR: \"+str(calculate_snr(A_S,background_signal)),\n",
    "                              \"Foreround SNR: \" + str(calculate_snr(A_S,foreground_signal))]\n",
    "            reportfile.write(\"\\n\".join(value_to_write))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV File\\Black Bloc - If You Want Success.stem.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanti\\AppData\\Local\\Temp\\ipykernel_3456\\1913312075.py:5: DeprecationWarning: Importing hamming from 'scipy.signal' is deprecated and will raise an error in SciPy 1.13.0. Please use 'scipy.signal.windows.hamming' or the convenience function 'scipy.signal.get_window' instead.\n",
      "  window_function = scipy.signal.hamming(window_length, sym=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "stft:  (2048, 17165, 2)\n",
      "WAV File\\Clara Berry And Wooldog - Stella.stem.wav\n",
      "<class 'int'>\n",
      "stft:  (2048, 8423, 2)\n",
      "WAV File\\James May - Dont Let Go.stem.wav\n",
      "<class 'int'>\n",
      "stft:  (2048, 10421, 2)\n",
      "WAV File\\Titanium - Haunted Age.stem.wav\n",
      "<class 'int'>\n",
      "stft:  (2048, 10686, 2)\n",
      "WAV File\\Wall Of Death - Femme.stem.wav\n",
      "<class 'int'>\n",
      "stft:  (2048, 10291, 2)\n"
     ]
    }
   ],
   "source": [
    "genReport(\"WAV File\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
